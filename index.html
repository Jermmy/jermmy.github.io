<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="In me the tiger sniffs the rose.">
<meta property="og:type" content="website">
<meta property="og:title" content="Jermmy&#39;s Lazy Blog">
<meta property="og:url" content="https://jermmy.github.io/index.html">
<meta property="og:site_name" content="Jermmy&#39;s Lazy Blog">
<meta property="og:description" content="In me the tiger sniffs the rose.">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jermmy&#39;s Lazy Blog">
<meta name="twitter:description" content="In me the tiger sniffs the rose.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://jermmy.github.io/"/>





  <title>Jermmy's Lazy Blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-84659849-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4d053879042f439aeb8fc5996a907b6b";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jermmy's Lazy Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2020/07/04/2020-7-4-post-training-quantization-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/04/2020-7-4-post-training-quantization-2/" itemprop="url">
                  神经网络量化入门--后训练量化
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-04T11:27:15+08:00">
                2020-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/07/04/2020-7-4-post-training-quantization-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/07/04/2020-7-4-post-training-quantization-2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2020/07/04/2020-7-4-post-training-quantization-2/" class="leancloud_visitors" data-flag-title="神经网络量化入门--后训练量化">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇<a href="http://jermmy.github.io/2020/06/13/2020-6-13-network-quantization-1-md/">文章</a>介绍了矩阵量化的基本原理，并推广到卷积网络中。这一章开始，我会逐步深入到卷积网络的量化细节中，并用 pytorch 从零搭建一个量化模型，帮助读者实际感受量化的具体流程。</p>
<p>本章中，我们来具体学习最简单的量化方法——后训练量化「post training quantization」</p>
<p>由于本人接触量化不久，如表述有错，欢迎指正。</p>
<h2 id="卷积层量化">卷积层量化</h2>
<p>卷积网络最核心的要素是卷积，前文虽然有提及卷积运算的量化，但省略了很多细节，本文继续深入卷积层的量化。</p>
<p>这里我们继续沿用之前的公式，用 <span class="math inline">\(S\)</span>、<span class="math inline">\(Z\)</span> 表示 scale 和 zero point，<span class="math inline">\(r\)</span> 表示浮点实数，<span class="math inline">\(q\)</span> 表示定点整数。</p>
<p>假设卷积的权重 weight 为 <span class="math inline">\(w\)</span>，bias 为 <span class="math inline">\(b\)</span>，输入为 <span class="math inline">\(x\)</span>，输出的激活值为 <span class="math inline">\(a\)</span>。由于卷积本质上就是矩阵运算，因此可以表示成: <span class="math display">\[
a=\sum_{i}^N w_i x_i+b \tag{1}
\]</span> 由此得到量化的公式: <span class="math display">\[
S_a (q_a-Z_a)=\sum_{i}^N S_w(q_w-Z_w)S_x(q_x-Z_x)+S_b(q_b-Z_b) \tag{2}
\]</span></p>
<p><span class="math display">\[
q_a=\frac{S_w S_x}{S_a}\sum_{i}^N (q_w-Z_w)(q_x-Z_x)+\frac{S_b}{S_a}(q_b-Z_b)+Z_a \tag{3}
\]</span></p>
<p>这里面非整数的部分就只有 <span class="math inline">\(\frac{S_w S_x}{S_a}\)</span>、<span class="math inline">\(\frac{S_b}{S_a}\)</span>，因此接下来就是把这部分也变成定点运算。</p>
<p>对于 bias，由于 <span class="math inline">\(\sum_{i}^N (q_w-Z_w)(q_x-Z_x)\)</span> 的结果通常会用 int32 的整数存储，因此 bias 通常也量化到 int32。这里我们可以直接用 <span class="math inline">\(S_w S_x\)</span> 来代替 <span class="math inline">\(S_b\)</span>，由于 <span class="math inline">\(S_w\)</span>、<span class="math inline">\(S_x\)</span> 都是对应 8 个 bit 的缩放比例，因此 <span class="math inline">\(S_w S_x\)</span> 最多就放缩到 16 个 bit，用 32bit 来存放 bias 绰绰有余，而 <span class="math inline">\(Z_b\)</span> 则直接记为 0。</p>
<p>因此，公式 (3) 再次调整为: <span class="math display">\[
\begin{align}
q_a&amp;=\frac{S_w S_x}{S_a}(\sum_{i}^N(q_w-Z_w)(q_x-Z_x)+q_b)+Z_a \notag \\
&amp;=M(\sum_{i}^N q_wq_x-\sum_i^N q_wZ_x-\sum_i^N q_xZ_w+\sum_i^NZ_wZ_x+q_b)+Z_a \tag{4}
\end{align}
\]</span> 其中，<span class="math inline">\(M=\frac{S_w S_x}{S_a}\)</span>。</p>
<p>根据上一篇文章的介绍，<span class="math inline">\(M\)</span> 可以通过一个定点小数加上 bit shift 来实现，因此公式 (4) 完全可以通过定点运算进行计算。由于 <span class="math inline">\(Z_w\)</span>、<span class="math inline">\(q_w\)</span>、<span class="math inline">\(Z_x\)</span>、<span class="math inline">\(q_b\)</span> 都是可以事先计算的，因此 <span class="math inline">\(\sum_i^N q_wZ_x\)</span>、<span class="math inline">\(\sum_i^NZ_wZ_x+q_b\)</span> 也可以事先计算好，实际 inference 的时候，只需要计算 <span class="math inline">\(\sum_{i}^N q_wq_x\)</span> 和 <span class="math inline">\(\sum_i^N q_xZ_w\)</span> 即可。</p>
<h2 id="卷积网络量化流程">卷积网络量化流程</h2>
<p>了解完整个卷积层的量化，现在我们再来完整过一遍卷积网络的量化流程。</p>
<p>我们继续沿用前文的小网络：</p>
<center>
<img src="/images/2020-7-4/net-eg.png" width="500px">
</center>
<p>其中，<span class="math inline">\(x\)</span>、<span class="math inline">\(y\)</span> 表示输入和输出，<span class="math inline">\(a_1\)</span>、<span class="math inline">\(a_2\)</span> 是网络中间的 feature map，<span class="math inline">\(q_x\)</span> 表示 <span class="math inline">\(x\)</span> 量化后的定点数，<span class="math inline">\(q_{a1}\)</span> 等同理。</p>
<p>在后训练量化中，我们需要一些样本来统计 <span class="math inline">\(x\)</span>、<span class="math inline">\(a_1\)</span>、<span class="math inline">\(a_2\)</span> 以及 <span class="math inline">\(y\)</span> 的数值范围「即 min, max」，再根据量化的位数以及量化方法来计算 scale 和 zero point。</p>
<p>本文中，我们先采用最简单的量化方式，即统计 min、max 后，按照线性量化公式: <span class="math display">\[
S = \frac{r_{max}-r_{min}}{q_{max}-q_{min}} \tag{5}
\]</span></p>
<p><span class="math display">\[
Z = round(q_{max} - \frac{r_{max}}{S}) \tag{6}
\]</span></p>
<p>来计算 scale 和 zero point。</p>
<p>需要注意的是，除了第一个 conv 需要统计输入 <span class="math inline">\(x\)</span> 的 min、max 外，其他层都只需要统计中间输出 feature 的 min、max 即可。另外，对于 relu、maxpooling 这类激活函数来说，它们会沿用上一层输出的 min、max，不需要额外统计，即上图中 <span class="math inline">\(a_1\)</span>、<span class="math inline">\(a_2\)</span> 会共享相同的 min、max 「为何这些激活函数可以共享 min max，以及哪些激活函数有这种性质，之后有时间可以细说」。</p>
<p>因此，在最简单的后训练量化算法中，我们会先按照正常的 forward 流程跑一些数据，在这个过程中，统计输入输出以及中间 feature map 的 min、max。等统计得差不多了，我们就可以根据 min、max 来计算 scale 和 zero point，然后根据公式 (4) 中的，对一些数据项提前计算。</p>
<p>之后，在 inference 的时候，我们会先把输入 <span class="math inline">\(x\)</span> 量化成定点整数 <span class="math inline">\(q_x\)</span>，然后按照公式 (4) 计算卷积的输出 <span class="math inline">\(q_{a1}\)</span>，这个结果依然是整型的，然后继续计算 relu 的输出 <span class="math inline">\(q_{a2}\)</span>。对于 fc 层来说，它本质上也是矩阵运算，因此也可以用公式 (4) 计算，然后得到 <span class="math inline">\(q_y\)</span>。最后，根据 fc 层已经计算出来的 scale 和 zero point，推算回浮点实数 <span class="math inline">\(y\)</span>。除了输入输出的量化和反量化操作，其他流程完全可以用定点运算来完成。</p>
<h2 id="pytorch实现">pytorch实现</h2>
<p>有了上面的铺垫，现在开始用 pytorch 从零搭建量化模型。</p>
<p>下文的代码都可以在 https://github.com/Jermmy/pytorch-quantization-demo 上找到。</p>
<h3 id="基础量化函数">基础量化函数</h3>
<p>首先，我们需要把量化的基本公式，也就是公式 (5)(6) 先实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcScaleZeroPoint</span><span class="params">(min_val, max_val, num_bits=<span class="number">8</span>)</span>:</span></span><br><span class="line">    qmin = <span class="number">0.</span></span><br><span class="line">    qmax = <span class="number">2.</span> ** num_bits - <span class="number">1.</span></span><br><span class="line">    scale = float((max_val - min_val) / (qmax - qmin)) <span class="comment"># S=(rmax-rmin)/(qmax-qmin)</span></span><br><span class="line"></span><br><span class="line">    zero_point = qmax - max_val / scale    <span class="comment"># Z=round(qmax-rmax/scale)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> zero_point &lt; qmin:</span><br><span class="line">        zero_point = qmin</span><br><span class="line">    <span class="keyword">elif</span> zero_point &gt; qmax:</span><br><span class="line">        zero_point = qmax</span><br><span class="line">    </span><br><span class="line">    zero_point = int(zero_point)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scale, zero_point</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantize_tensor</span><span class="params">(x, scale, zero_point, num_bits=<span class="number">8</span>, signed=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> signed:</span><br><span class="line">        qmin = - <span class="number">2.</span> ** (num_bits - <span class="number">1</span>)</span><br><span class="line">        qmax = <span class="number">2.</span> ** (num_bits - <span class="number">1</span>) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        qmin = <span class="number">0.</span></span><br><span class="line">        qmax = <span class="number">2.</span>**num_bits - <span class="number">1.</span></span><br><span class="line"> </span><br><span class="line">    q_x = zero_point + x / scale</span><br><span class="line">    q_x.clamp_(qmin, qmax).round_()     <span class="comment"># q=round(r/S+Z)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> q_x.float()  <span class="comment"># 由于pytorch不支持int类型的运算，因此我们还是用float来表示整数</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dequantize_tensor</span><span class="params">(q_x, scale, zero_point)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> scale * (q_x - zero_point)    <span class="comment"># r=S(q-Z)</span></span><br></pre></td></tr></table></figure>
<p>前面提到，在后训练量化过程中，需要先统计样本以及中间层的 min、max，同时也频繁涉及到一些量化、反量化操作，因此我们可以把这些功能都封装成一个 <code>QParam</code> 类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QParam</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_bits=<span class="number">8</span>)</span>:</span></span><br><span class="line">        self.num_bits = num_bits</span><br><span class="line">        self.scale = <span class="keyword">None</span></span><br><span class="line">        self.zero_point = <span class="keyword">None</span></span><br><span class="line">        self.min = <span class="keyword">None</span></span><br><span class="line">        self.max = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, tensor)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.max <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> self.max &lt; tensor.max():</span><br><span class="line">            self.max = tensor.max()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.min <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> self.min &gt; tensor.min():</span><br><span class="line">            self.min = tensor.min()</span><br><span class="line">        </span><br><span class="line">        self.scale, self.zero_point = calcScaleZeroPoint(self.min, self.max, self.num_bits)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize_tensor</span><span class="params">(self, tensor)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> quantize_tensor(tensor, self.scale, self.zero_point, num_bits=self.num_bits)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dequantize_tensor</span><span class="params">(self, q_x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> dequantize_tensor(q_x, self.scale, self.zero_point)</span><br></pre></td></tr></table></figure>
<p>上面的 <code>update</code> 函数就是用来统计 min、max 的。</p>
<h3 id="量化网络模块">量化网络模块</h3>
<p>下面要来实现一些最基本网络模块的量化形式，包括 conv、relu、maxpooling 以及 fc 层。</p>
<p>首先我们定义一个量化基类，这样可以减少一些重复代码，也能让代码结构更加清晰：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, qi=True, qo=True, num_bits=<span class="number">8</span>)</span>:</span></span><br><span class="line">        super(QModule, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> qi:</span><br><span class="line">            self.qi = QParam(num_bits=num_bits)</span><br><span class="line">        <span class="keyword">if</span> qo:</span><br><span class="line">            self.qo = QParam(num_bits=num_bits)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">freeze</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize_inference</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(<span class="string">'quantize_inference should be implemented.'</span>)</span><br></pre></td></tr></table></figure>
<p>这个基类规定了每个量化模块都需要提供的方法。</p>
<p>首先是 <code>__init__</code> 函数，除了指定量化的位数外，还需指定是否提供量化输入 (qi) 及输出参数 (qo)。在前面也提到，不是每一个网络模块都需要统计输入的 min、max，大部分中间层都是用上一层的 qo 来作为自己的 qi 的，另外有些中间层的激活函数也是直接用上一层的 qi 来作为自己的 qi 和 qo。</p>
<p>其次是 <code>freeze</code> 函数，这个函数会在统计完 min、max 后发挥作用。正如上文所说的，公式 (4) 中有很多项是可以提前计算好的，freeze 就是把这些项提前固定下来，同时也将网络的权重由<strong>浮点实数</strong>转化为<strong>定点整数</strong>。</p>
<p>最后是 <code>quantize_inference</code>，这个函数主要是量化 inference 的时候会使用。实际 inference 的时候和正常的 forward 会有一些差异，可以根据之后的代码体会一下。</p>
<p>下面重点看量化卷积层的实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QConv2d</span><span class="params">(QModule)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, conv_module, qi=True, qo=True, num_bits=<span class="number">8</span>)</span>:</span></span><br><span class="line">        super(QConv2d, self).__init__(qi=qi, qo=qo, num_bits=num_bits)</span><br><span class="line">        self.num_bits = num_bits</span><br><span class="line">        self.conv_module = conv_module</span><br><span class="line">        self.qw = QParam(num_bits=num_bits)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">freeze</span><span class="params">(self, qi=None, qo=None)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'qi'</span>) <span class="keyword">and</span> qi <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'qi has been provided in init function.'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'qi'</span>) <span class="keyword">and</span> qi <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'qi is not existed, should be provided.'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'qo'</span>) <span class="keyword">and</span> qo <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'qo has been provided in init function.'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'qo'</span>) <span class="keyword">and</span> qo <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'qo is not existed, should be provided.'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> qi <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.qi = qi</span><br><span class="line">        <span class="keyword">if</span> qo <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.qo = qo</span><br><span class="line">        self.M = self.qw.scale * self.qi.scale / self.qo.scale</span><br><span class="line"></span><br><span class="line">        self.conv_module.weight.data = self.qw.quantize_tensor(self.conv_module.weight.data)</span><br><span class="line">        self.conv_module.weight.data = self.conv_module.weight.data - self.qw.zero_point</span><br><span class="line"></span><br><span class="line">        self.conv_module.bias.data = quantize_tensor(self.conv_module.bias.data, scale=self.qi.scale * self.qw.scale, zero_point=<span class="number">0</span>, signed=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'qi'</span>):</span><br><span class="line">            self.qi.update(x)</span><br><span class="line"></span><br><span class="line">        self.qw.update(self.conv_module.weight.data)</span><br><span class="line"></span><br><span class="line">        self.conv_module.weight.data = self.qw.quantize_tensor(self.conv_module.weight.data)</span><br><span class="line">        self.conv_module.weight.data = self.qw.dequantize_tensor(self.conv_module.weight.data)</span><br><span class="line"></span><br><span class="line">        x = self.conv_module(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'qo'</span>):</span><br><span class="line">            self.qo.update(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize_inference</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x - self.qi.zero_point</span><br><span class="line">        x = self.fc_module(x)</span><br><span class="line">        x = self.M * x + self.qo.zero_point</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>这个类基本涵盖了最精华的部分。</p>
<p>首先是 <code>__init__</code> 函数，可以看到我传入了一个 <code>conv_module</code> 模块，这个模块对应全精度的卷积层，另外的 <code>qw</code> 参数则是用来统计 weight 的 min、max 以及对 weight 进行量化用的。</p>
<p>其次是 <code>freeze</code> 函数，这个函数主要就是计算公式 (4) 中的 <span class="math inline">\(M\)</span>、<span class="math inline">\(q_w\)</span> 以及 <span class="math inline">\(q_b\)</span>。由于完全实现公式 (4) 的加速效果需要更底层代码的支持，因此在 pytorch 中我用了更简单的实现方式，即优化前的公式 (4): <span class="math display">\[
q_a=M(\sum_{i}^N(q_w-Z_w)(q_x-Z_x)+q_b)+Z_a \tag{7}
\]</span> 这里的 <span class="math inline">\(M\)</span> 本来也需要通过移位来实现定点化加速，但 pytorch 中 bit shift 操作不好实现，因此我们还是用原始的乘法操作来代替。</p>
<p>注意到 freeze 函数可能会传入 qi 或者 qo​，这也是之前提到的，有些中间的模块不会有自己的 qi，而是复用之前层的 qo 作为自己的 qi。</p>
<p>接着是 <code>forward</code> 函数，这个函数和正常的 forward 一样，也是在 float 上进行的，只不过需要统计输入输出以及 weight 的 min、max 而已。有读者可能会疑惑为什么需要对 weight 量化到 int8 然后又反量化回 float，这里其实就是所谓的伪量化节点，因为我们在实际量化 inference 的时候会把 weight 量化到 int8，这个过程本身是有精度损失的 (来自四舍五入的 round 带来的截断误差)，所以在统计 min、max 的时候，需要把这个过程带来的误差也模拟进去。</p>
<p>最后是 <code>quantize_inference</code> 函数，这个函数在实际 inference 的时候会被调用，对应的就是上面的公式 (7)。注意，这个函数里面的卷积操作是在 int 上进行的，这是量化推理加速的关键「当然，由于 pytorch 的限制，我们仍然是在 float 上计算，只不过数值都是整数。这也可以看出量化推理是跟底层实现紧密结合的技术」。</p>
<p>理解 <code>QConv2d</code> 后，其他模块基本上异曲同工，这里不再赘述。</p>
<h3 id="完整的量化网络">完整的量化网络</h3>
<p>我们定义一个简单的卷积网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_channels=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(num_channels, <span class="number">40</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">40</span>, <span class="number">40</span>, <span class="number">3</span>, <span class="number">1</span>, groups=<span class="number">20</span>) <span class="comment"># 这里用分组网络，可以增大量化带来的误差</span></span><br><span class="line">        self.fc = nn.Linear(<span class="number">5</span>*<span class="number">5</span>*<span class="number">40</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">5</span>*<span class="number">5</span>*<span class="number">40</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>接下来就是把这个网络的每个模块进行量化，我们单独定义一个 <code>quantize</code> 函数来逐个量化每个模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize</span><span class="params">(self, num_bits=<span class="number">8</span>)</span>:</span></span><br><span class="line">        self.qconv1 = QConv2d(self.conv1, qi=<span class="keyword">True</span>, qo=<span class="keyword">True</span>, num_bits=num_bits)</span><br><span class="line">        self.qrelu1 = QReLU()</span><br><span class="line">        self.qmaxpool2d_1 = QMaxPooling2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.qconv2 = QConv2d(self.conv2, qi=<span class="keyword">False</span>, qo=<span class="keyword">True</span>, num_bits=num_bits)</span><br><span class="line">        self.qrelu2 = QReLU()</span><br><span class="line">        self.qmaxpool2d_2 = QMaxPooling2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.qfc = QLinear(self.fc, qi=<span class="keyword">False</span>, qo=<span class="keyword">True</span>, num_bits=num_bits)</span><br></pre></td></tr></table></figure>
<p>注意，这里只有第一层的 conv 需要 qi，后面的模块基本是复用前面层的 qo 作为当前层的 qi。</p>
<p>接着定义一个 quantize_forward 函数来统计 min、max，同时模拟量化误差：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize_forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.qconv1(x)</span><br><span class="line">        x = self.qrelu1(x)</span><br><span class="line">        x = self.qmaxpool2d_1(x)</span><br><span class="line">        x = self.qconv2(x)</span><br><span class="line">        x = self.qrelu2(x)</span><br><span class="line">        x = self.qmaxpool2d_2(x)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">5</span>*<span class="number">5</span>*<span class="number">40</span>)</span><br><span class="line">        x = self.qfc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>下面的 <code>freeze</code> 函数会在统计完 min、max 后对一些变量进行固化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">freeze</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.qconv1.freeze()</span><br><span class="line">        self.qrelu1.freeze(self.qconv1.qo)</span><br><span class="line">        self.qmaxpool2d_1.freeze(self.qconv1.qo)</span><br><span class="line">        self.qconv2.freeze(qi=self.qconv1.qo)</span><br><span class="line">        self.qrelu2.freeze(self.qconv2.qo)</span><br><span class="line">        self.qmaxpool2d_2.freeze(self.qconv2.qo)</span><br><span class="line">        self.qfc.freeze(qi=self.qconv2.qo)</span><br></pre></td></tr></table></figure>
<p>由于我们在量化网络的时候，有些模块是没有定义 qi 的，因此这里需要传入前面层的 qo 作为当前层的 qi。</p>
<p>最后是 <code>quantize_inference</code> 函数，就是实际 inference 的时候用到的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quantize_inference</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        qx = self.qconv1.qi.quantize_tensor(x)</span><br><span class="line">        qx = self.qconv1.quantize_inference(qx)</span><br><span class="line">        qx = self.qrelu1.quantize_inference(qx)</span><br><span class="line">        qx = self.qmaxpool2d_1.quantize_inference(qx)</span><br><span class="line">        qx = self.qconv2.quantize_inference(qx)</span><br><span class="line">        qx = self.qrelu2.quantize_inference(qx)</span><br><span class="line">        qx = self.qmaxpool2d_2.quantize_inference(qx)</span><br><span class="line">        qx = qx.view(<span class="number">-1</span>, <span class="number">5</span>*<span class="number">5</span>*<span class="number">40</span>)</span><br><span class="line">        qx = self.qfc.quantize_inference(qx)</span><br><span class="line">        out = self.qfc.qo.dequantize_tensor(qx)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>这里我们会将输入 <code>x</code> 先量化到 int8，然后就是全量化的定点运算，得到最后一层的输出后，再反量化回 float 即可。</p>
<h3 id="训练全精度网络">训练全精度网络</h3>
<p>这一部分代码在 train.py 中，我们用 mnist 数据集来训练上面的网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">'data'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, </span><br><span class="line">                 transform=transforms.Compose([</span><br><span class="line">                   transforms.ToTensor(),</span><br><span class="line">                   transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                 ])),</span><br><span class="line">  batch_size=batch_size, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">1</span>, pin_memory=<span class="keyword">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">'data'</span>, train=<span class="keyword">False</span>, transform=transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">  ])),</span><br><span class="line">  batch_size=test_batch_size, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">1</span>, pin_memory=<span class="keyword">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = Net().to(device)</span><br></pre></td></tr></table></figure>
<p>具体训练细节比较简单，这里不再赘述。</p>
<p>训练完成后，我测试得到的准确率在 98% 左右。</p>
<h3 id="后训练量化">后训练量化</h3>
<p>这一部分代码在 post_training_quantize.py 中。</p>
<p>我们先加载全精度模型的参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Net()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">'ckpt/mnist_cnn.pt'</span>))</span><br></pre></td></tr></table></figure>
<p>然后对网络进行量化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.quantize(num_bits=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>接下来就是用一些训练数据来估计 min、max：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">direct_quantize</span><span class="params">(model, test_loader)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i, (data, target) <span class="keyword">in</span> enumerate(test_loader, <span class="number">1</span>):</span><br><span class="line">        output = model.quantize_forward(data)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">'direct quantization finish'</span>)</span><br></pre></td></tr></table></figure>
<p>简单起见，我们就跑 200 个迭代。</p>
<p>然后，我们把量化参数都固定下来，并进行全量化推理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model.freeze()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantize_inference</span><span class="params">(model, test_loader)</span>:</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, (data, target) <span class="keyword">in</span> enumerate(test_loader, <span class="number">1</span>):</span><br><span class="line">        output = model.quantize_inference(data)</span><br><span class="line">        pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">        correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line">    print(<span class="string">'\nTest set: Quant Model Accuracy: &#123;:.0f&#125;%\n'</span>.format(<span class="number">100.</span> * correct / len(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line">quantize_inference(model, test_loader)</span><br></pre></td></tr></table></figure>
<p>由于很多细节都封装在量化网络的模块中了，因此外部调用的代码跟全精度模型其实很类似。</p>
<p>我自己测试了 bit 数为 1～8 的准确率，得到下面这张折线图：</p>
<center>
<img src="/images/2020-7-4/acc.png" width="500px">
</center>
<p>发现，当 bit &gt;= 3 的时候，精度几乎不会掉，bit = 2 的时候精度下降到 69%，bit = 1 的时候则下降到 10%。</p>
<p>这一方面是 mnist 分类任务比较简单，但也说明神经网络中的冗余量其实非常大，所以量化在分类网络中普遍有不错的效果「不过 bit =3 或 4 的时候效果依然这么好，让我依稀觉得代码里面应该有 bug，后续还要反复检查」。</p>
<h2 id="总结">总结</h2>
<p>这篇文章主要补充了卷积层量化的细节，包括 bias 的量化，以及实际 inference 时一些优化的操作。并梳理了完整的卷积网络量化的流程。然后重点用 pytorch 从零搭建一个量化模型来帮助大家理解其中的细节，以及后训练量化算法的过程。代码是参考了这篇<a href="https://medium.com/@karanbirchahal/how-to-quantise-an-mnist-network-to-8-bits-in-pytorch-no-retraining-required-from-scratch-39f634ac8459" target="_blank" rel="noopener">文章</a>，加上自己拍脑袋构思的，存在很多不足之处，而且应该有不少 bug 存在，也欢迎大家指正。</p>
<p>之后的文章将继续讲述量化感知训练的流程，并补充其他量化的细节「例如 conv+relu 的合并等」，感谢大家赏脸关注。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://medium.com/@karanbirchahal/how-to-quantise-an-mnist-network-to-8-bits-in-pytorch-no-retraining-required-from-scratch-39f634ac8459" target="_blank" rel="noopener">How to Quantize an MNIST network to 8 bits in Pytorch from scratch (No retraining required)</a></li>
<li><a href="https://arxiv.org/abs/1712.05877" target="_blank" rel="noopener">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2020/06/13/2020-6-13-network-quantization-1-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/13/2020-6-13-network-quantization-1-md/" itemprop="url">
                  神经网络量化入门--基本原理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-13T19:47:47+08:00">
                2020-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/06/13/2020-6-13-network-quantization-1-md/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/06/13/2020-6-13-network-quantization-1-md/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2020/06/13/2020-6-13-network-quantization-1-md/" class="leancloud_visitors" data-flag-title="神经网络量化入门--基本原理">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>最近打算写一个关于神经网络量化的入门教程，包括网络量化的基本原理、离线量化、量化训练，以及全量化模型的推理过程，最后我会用 pytorch 从零构建一个量化模型，帮助读者形成更深刻的理解。</p>
<p>之所以要写这系列教程，主要是想帮助初次接触量化的同学快速入门。笔者在刚开始接触模型量化时走了很多弯路，并且发现网上的资料和论文对初学者来说太不友好。目前学术界的量化方法都过于花俏，能落地的极少，工业界广泛使用的还是 Google TFLite 那一套量化方法，而 TFLite 对应的大部分资料都只告诉你如何使用，能讲清楚原理的也非常少。这系列教程不会涉及学术上那些花俏的量化方法，主要是想介绍工业界用得最多的量化方案 (即 TFLite 的量化原理，对应 Google 的论文 <a href="https://arxiv.org/abs/1712.05877" target="_blank" rel="noopener">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a> )</p>
<p>话不多说，我们开始。这一章中，主要介绍网络量化的基本原理，以及推理的时候如何跑量化模型。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/06/13/2020-6-13-network-quantization-1-md/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/" itemprop="url">
                  让计算机审美，这可能吗?
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-06T22:37:29+08:00">
                2019-08-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机视觉/" itemprop="url" rel="index">
                    <span itemprop="name">计算机视觉</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/" class="leancloud_visitors" data-flag-title="让计算机审美，这可能吗?">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>这一个月来一直在研究计算机美学 (photo aesthetic) 的课题，因为有一个需求是帮助用户筛选出一些拍的比较好的图片。这段时间陆陆续续看了很多相关的文章，也一直在思考这个问题：让计算机来对图片进行审美，到底有没有可能？毕竟审美是一件很主观的事情，美的定义本身也不清晰，让需要明确指令的计算机来做一件人类都不明确的事情，这看起来就不太现实。</p>
<p>本文会记录一下我最近看过的一些文章，总结一下这个领域的研究思路，以及我个人的一些想法。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/08/06/2019-8-6-is-it-possibile-for-computer-to-be-aesthetic/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2019/05/12/2019-5-12-pytorch-cpp-extension/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/05/12/2019-5-12-pytorch-cpp-extension/" itemprop="url">
                  PyTorch中的C++扩展
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-12T23:47:07+08:00">
                2019-05-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/12/2019-5-12-pytorch-cpp-extension/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/05/12/2019-5-12-pytorch-cpp-extension/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/05/12/2019-5-12-pytorch-cpp-extension/" class="leancloud_visitors" data-flag-title="PyTorch中的C++扩展">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>今天要聊聊用 PyTorch 进行 C++ 扩展。</p>
<p>在正式开始前，我们需要了解 PyTorch 如何自定义 <code>module</code>。这其中，最常见的就是在 python 中继承 <code>torch.nn.Module</code>，用 PyTorch 中已有的 operator 来组装成自己的模块。这种方式实现简单，但是，计算效率却未必最佳，另外，如果我们想实现的功能过于复杂，可能 PyTorch 中那些已有的函数也没法满足我们的要求。这时，用 C、C++、CUDA 来扩展 PyTorch 的模块就是最佳的选择了。</p>
<p>由于目前市面上大部分深度学习系统（TensorFlow、PyTorch 等）都是基于 C、C++ 构建的后端，因此这些系统基本都存在 C、C++ 的扩展接口。PyTorch 是基于 Torch 构建的，而 Torch 底层采用的是 C 语言，因此 PyTorch 天生就和 C 兼容，因此用 C 来扩展 PyTorch 并非难事。而随着 PyTorch1.0 的发布，官方已经开始考虑将 PyTorch 的底层代码用 caffe2 替换，因此他们也在逐步重构 ATen，后者是目前 PyTorch 使用的 C++ 扩展库。总的来说，C++ 是未来的趋势。至于 CUDA，这是几乎所有深度学习系统在构建之初就采用的工具，因此 CUDA 的扩展接口是标配。</p>
<p>本文用一个简单的例子，梳理一下进行 C++ 扩展的步骤，至于一些具体的实现，不做深入探讨。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/05/12/2019-5-12-pytorch-cpp-extension/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2019/04/12/2019-4-12-paper-notes-mask-rcnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/04/12/2019-4-12-paper-notes-mask-rcnn/" itemprop="url">
                  论文笔记：Mask R-CNN
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-12T23:41:11+08:00">
                2019-04-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机视觉/" itemprop="url" rel="index">
                    <span itemprop="name">计算机视觉</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/12/2019-4-12-paper-notes-mask-rcnn/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/12/2019-4-12-paper-notes-mask-rcnn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/04/12/2019-4-12-paper-notes-mask-rcnn/" class="leancloud_visitors" data-flag-title="论文笔记：Mask R-CNN">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>之前在一次组会上，师弟诉苦说他用 UNet 处理一个病灶分割的任务，但效果极差，我看了他的数据后发现，那些病灶区域比起整张图而言非常的小，而 UNet 采用的损失函数通常是逐像素的分类损失，如此一来，网络只要能够分割出大部分背景，那么 loss 的值就可以下降很多，自然无法精细地分割出那些细小的病灶。反过来想，这其实类似于正负样本极不均衡的情况，网络拟合了大部分负样本后，即使正样本拟合得较差，整体的 loss 也已经很低了。</p>
<p>发现这个问题后，我就在想可不可以先用 Faster RCNN 之类的先检测出这些病灶区域的候选框，再在框内做分割，甚至，能不能直接把 Faster RCNN 和分割部分做成一个统一的模型来处理。后来发现，这不就是 Mask RCNN 做的事情咩～囧～</p>
<p>这篇文章，我们就从无到有来看看 Mask RCNN 是怎么设计出来的。</p>
<center>
<img src="/images/2019-4-12/mask-rcnn.png" width="700px">
</center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/04/12/2019-4-12-paper-notes-mask-rcnn/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2019/01/03/2019-1-1-from-2018-to-2019/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/01/03/2019-1-1-from-2018-to-2019/" itemprop="url">
                  从2018走来
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-03T15:28:55+08:00">
                2019-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/杂感/" itemprop="url" rel="index">
                    <span itemprop="name">杂感</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/01/03/2019-1-1-from-2018-to-2019/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/01/03/2019-1-1-from-2018-to-2019/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/01/03/2019-1-1-from-2018-to-2019/" class="leancloud_visitors" data-flag-title="从2018走来">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>过去一直没有做年终总结的习惯，因为我之前的习惯是脚踏实地的做完眼前的小事情，也从来没给自己确立过什么目标，因此年终的时候也就平平无奇，既没有那种水到渠成的坦然，也没有那种吹尽狂沙始到金的欣慰。但 2018 确实给我带来了不少成长，也是我这些年来过得最不淡定的一年，有些不淡定可能会一直延续到 2019。在我真正能做到拨云见日之前，希望这篇文章能为今后的决定提供一些勇气和思路。</p>
<center>
<img src="/images/2019-1-3/new-year.jpg" width="300px">
</center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/01/03/2019-1-1-from-2018-to-2019/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2018/12/02/2018-12-2-one-day-in-guilin/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/12/02/2018-12-2-one-day-in-guilin/" itemprop="url">
                  One Day in 桂林
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-02T19:59:09+08:00">
                2018-12-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/杂感/" itemprop="url" rel="index">
                    <span itemprop="name">杂感</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/12/02/2018-12-2-one-day-in-guilin/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/12/02/2018-12-2-one-day-in-guilin/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/12/02/2018-12-2-one-day-in-guilin/" class="leancloud_visitors" data-flag-title="One Day in 桂林">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>这两天导师让我到桂林参加一个学术会议，不过由于会议太水，加之我出发得太晚，等到桂林的时候，会议差不多结束了。我想我也不能无功而返，就趁着公费出差的机会，在这个号称「山水甲天下」的城市，以一个单身狗该有的心态逛了一圈。</p>
<center>
<img src="/images/2018-12-2/elephant-mountain.jpg" width="400px">
<figcaption>
「语文课本中的象鼻山」
</figcaption>
</center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/12/02/2018-12-2-one-day-in-guilin/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/" itemprop="url">
                  RNN，写起来真的烦
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-25T17:49:42+08:00">
                2018-11-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/" class="leancloud_visitors" data-flag-title="RNN，写起来真的烦">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>曾经，为了处理一些序列相关的数据，我稍微了解了一点递归网络 (RNN) 的东西。由于当时只会 tensorflow，就从官网上找了一些 tensorflow 相关的 demo，中间陆陆续续折腾了两个多星期，才对 squence to sequence，sequence classification 这些常见的模型和代码有了一些肤浅的认识。虽然只是多了<strong>时间</strong>这个维度，但 RNN 相关的东西，不仅是模型搭建上，在数据处理方面的繁琐程度也比 CNN 要高一个 level。另外，我也是从那个时候开始对 tensorflow 产生抵触心理，在 tf 中，你知道 RNN 有几种写法吗？你知道 dynamic_rnn 和 static_rnn 有什么区别吗？各种纷繁复杂的概念无疑加大了初学者的门槛。后来我花了一两天的时间转向 pytorch 后，感觉整个世界瞬间清净了 (当然了，学 tf 的好处就是转其他框架的时候非常快，但从其他框架转 tf 却可能生不如死)。pytorch 在模型搭建和数据处理方面都非常好上手，比起 tf 而言，代码写起来更加整洁干净，而且开发人员更容易理解代码的运作流程。不过，在 RNN 这个问题上，新手还是容易犯嘀咕。趁着这一周刚刚摸清了 pytorch 搭建 RNN 的套路，我准备记录一下用 pytorch 搭建 RNN 的基本流程，以及数据处理方面要注意的问题，希望后来的同学们少流点血泪…</p>
<p>至于 tf 怎么写 RNN，之后有闲再补上 (我现在是真的不想回去碰那颗烫手的山芋😩)</p>
<center>
<img src="/images/2018-11-25/rnn.png">
</center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/11/25/2018-11-25-how-to-write-rnn-in-pytorch-and-tensorflow/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/" itemprop="url">
                  论文笔记：Learning warped guidance for blind face restoration
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-03T16:18:38+08:00">
                2018-10-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机视觉/" itemprop="url" rel="index">
                    <span itemprop="name">计算机视觉</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/" class="leancloud_visitors" data-flag-title="论文笔记：Learning warped guidance for blind face restoration">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>这篇论文主要是讲人脸修复的，所谓人脸修复，其实就是将低清的，或者经过压缩等操作的人脸图像进行高清复原。这可以近似为针对人脸的图像修复工作。在图像修复中，我们都会假设退化的图像是高清图像经过某种函数映射后得到的（比如，由高清图像得到一张模糊的图像可能是使用了高斯模糊核），因此，图像修复的本质就是把这个函数映射找出来。由于神经网络可以近似任意函数，因此在深度学习时代，图像修复已经是一个被解决得比较好的问题了。比如，在图像去噪或者超分任务中，U-Net、FCN 之类的网络结构已经成为标配了。</p>
<p>不过，针对人脸的图像修复则是一个更为严苛的任务。原因主要是以下两点：</p>
<ol type="1">
<li>对于一般的图像，大家可能不会太在意细节恢复得好还是差，但对于人脸来说，由于这是人类最熟悉的部分，因此人脸中的很多细节，如一些皱纹、酒窝等都需要恢复出来才能让人满意，因此，这是一个粒度更细的图像修复任务。</li>
<li>另外，通常的图像修复都是针对一种退化场景设计的，比如，在去噪任务中，可能就只是针对某种或某几种噪声而言，而不考虑图像模糊等其他因素，因此任务相对简单。但如果退化的种类太多，退化函数本身可能会非常复杂，即使神经网络也未必能近似出来。正如标题中 <strong>blind</strong> 所言，退化函数的类型、数量我们是无法事先获悉的。事实上，论文考虑了 jpeg 压缩、高斯模糊、高斯噪声、图片放缩等退化方式，并且对每种方式进行随机组合，因此退化函数是非常复杂的。</li>
</ol>
<center>
<img src="/images/2018-10-3/network-arch.jpg" width="600px">
</center>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/10/03/2018-10-3-paper-note-learning-warped-guidance-for-blind-face-restoration/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://jermmy.github.io/2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jermmy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jermmy's Lazy Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/" itemprop="url">
                  如何在手机上跑深度神经网络
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T13:20:37+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/" class="leancloud_visitors" data-flag-title="如何在手机上跑深度神经网络">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <p>这天，老板跟你说，希望能在手机上跑深度神经网络，并且准确率要和 VGG、GoogleNet 差不多。</p>
<p>接到这个任务后你有点懵逼，这些网络别说计算量大，就连网络参数也要 100MB 的空间才存得下，放在手机上跑？开玩笑呗。</p>
<p>老板又说，怎么实现是你的事，我要的只是这个功能。</p>
<p>你默默地点了点头。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/08/04/2018-8-4-how-to-run-deep-learning-on-mobile/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Jermmy" />
          <p class="site-author-name" itemprop="name">Jermmy</p>
           
              <p class="site-description motion-element" itemprop="description">In me the tiger sniffs the rose.</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">91</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/jermmy" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.ruanyifeng.com/blog/" title="阮一峰" target="_blank">阮一峰</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://freemind.pluskid.org/" title="pluskid" target="_blank">pluskid</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jermmy</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://jermmy.disqus.com/count.js" async></script>
    

    

  




	





  





  








  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("FfkJQoNEh55mO6eDSUYJj0i1-gzGzoHsz", "sjxRrTn3UCxYsAQceJKYEfO7");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
